{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Project: Web Traffic Forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "from pipeline import *\n",
    "from cross_validation import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (24, 12)\n",
    "matplotlib.rcParams['lines.linewidth'] = 2\n",
    "matplotlib.rcParams['xtick.labelsize'] = 18\n",
    "matplotlib.rcParams['ytick.labelsize'] = 18\n",
    "matplotlib.rcParams['xtick.color'] = 'w'\n",
    "matplotlib.rcParams['ytick.color'] = 'w'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_timeseries(path):\n",
    "    df = pd.read_csv(path)\n",
    "    timeseries = {}\n",
    "    print(\"Loading timeseries:\")\n",
    "    for i, row in df.iterrows():\n",
    "        ts = pd.DataFrame({\"ds\": row.index[1:], \"views\": row.values[1:]})\n",
    "        timeseries[row.Page] = ts\n",
    "        print(row.Page)\n",
    "        #plt.plot(ts[\"ds\"], np.log(ts[\"y\"]))\n",
    "        #plt.xticks(rotation=90)\n",
    "        #plt.show()\n",
    "    return timeseries\n",
    "\n",
    "FPATH = \"./data/nfl_teams.csv\"\n",
    "timeseries = get_timeseries(FPATH)\n",
    "\n",
    "# Load data into DataFrame\n",
    "pages = [\"Atlanta_Falcons_en.wikipedia.org_mobile-web_all-agents\", \n",
    "         \"Dallas_Cowboys_en.wikipedia.org_mobile-web_all-agents\"]\n",
    "#pages = list(timeseries.keys())[:-1]\n",
    "ts_dfs = []\n",
    "for p in pages:\n",
    "    print(\"Preparing timeseries %s\" % p)\n",
    "    df = setup_dataframe(timeseries[p])\n",
    "    ts_dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Split history (train) and future (test)\n",
    "sdate = pd.datetime(2017, 7, 10)\n",
    "ts_data = []\n",
    "for df in ts_dfs: \n",
    "    history, future, y_scale = split_train_test(df, sdate)\n",
    "    ts_data.append({\n",
    "        \"history\": history, \"future\": future, \"y_scale\": y_scale\n",
    "    })\n",
    "    \n",
    "print(\"Extracting features\")\n",
    "ts = ts_data[0] # same feature matrix for all test series  \n",
    "train_data = extract_features(ts[\"history\"])\n",
    "test_data = extract_features(ts[\"future\"], changepoints_t=train_data[\"t_change\"])\n",
    "assert(all(train_data[\"X\"].columns ==  test_data[\"X\"].columns))\n",
    "assert(all(train_data[\"t_change\"] == test_data[\"t_change\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_results(ts_data, predictions, metrics):\n",
    "    for i, df in enumerate(ts_dfs):\n",
    "        plt.plot(ts_data[i][\"future\"][\"ds\"], ts_data[i][\"future\"][\"y_scaled\"])\n",
    "        plt.plot(predictions[i][\"ds\"], predictions[i][\"y_scaled_pred\"], '#2ca02c')\n",
    "        plt.show()  \n",
    "    m_pd = pd.DataFrame.from_dict(metrics)\n",
    "    m_pd.loc['mean'] = m_pd.mean()\n",
    "    print(m_pd)\n",
    "    print()\n",
    "\n",
    "def visualize_cross_validation(ts_dfs, predictions, metrics):\n",
    "    for i, df in enumerate(ts_dfs):\n",
    "        df = df[df[\"ds\"] > pd.datetime(2016,6,1)]\n",
    "        plt.plot(df[\"ds\"], df[\"y\"])\n",
    "        for pred in predictions:\n",
    "            plt.plot(pred[i][\"ds\"], pred[i][\"y_pred\"], '#2ca02c')\n",
    "        plt.show()\n",
    "    \n",
    "    metrics_df = pd.DataFrame(columns=['start', 'end', 'MAPE_avg', 'SMAPE_avg'])\n",
    "    for i, m_cutoff in enumerate(metrics):\n",
    "        dmin, dmax = predictions[i][0][\"ds\"].min(), predictions[i][0][\"ds\"].max()\n",
    "        avg_mape_scaled = np.mean([m[\"MAPE\"] for m in m_cutoff])\n",
    "        avg_smape_scaled = np.mean([m[\"SMAPE\"] for m in m_cutoff])\n",
    "        metrics_df = metrics_df.append({\"start\": dmin,\n",
    "                                        \"end\": dmax,\n",
    "                                        \"MAPE_avg\": avg_mape_scaled, \n",
    "                                        \"SMAPE_avg\": avg_smape_scaled}, ignore_index=True)\n",
    "    \n",
    "    print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in [Model1(), Model2(), Model3()]:\n",
    "    p, m = pipeline(ts_data, model,train_data, test_data, ITR=5000)\n",
    "    results.append({\"predictions\": p, \"metrics\": m})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, r in enumerate(results):\n",
    "    print(\"Model %d\" % i)\n",
    "    visualize_results(ts_data, r[\"predictions\"], r[\"metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def median_model(train, size, p=-50):\n",
    "#     visits = np.nan_to_num(np.nanmedian(train[-p:]))\n",
    "#     return np.ones(size) * visits\n",
    "\n",
    "# for i, ts in enumerate(ts_data):\n",
    "#     print(\"Median model for %d\" % i)\n",
    "#     y_true = ts[\"future\"][\"y_scaled\"]\n",
    "#     y_pred_median = median_model(ts[\"history\"][\"y_scaled\"], len(y_true))\n",
    "#     evaluate(y_true, y_pred_median)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "predictions, metrics = cross_validation(ts_dfs, Model1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_cross_validation(ts_dfs, predictions, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "predictions2, metrics2 = cross_validation(ts_dfs, Model2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_cross_validation(ts_dfs, predictions2, metrics2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "predictions3, metrics3 = cross_validation(ts_dfs, Model3())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_cross_validation(ts_dfs, predictions3, metrics3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training error \n",
    "# y_train_pred = np.array([sess.run([y_post], \n",
    "#                                   feed_dict={t: X_train['t'],\n",
    "#                                              A: X_train['A'], X: X_train['X'].as_matrix(), \n",
    "#                                              sigmas: X_train['sigmas'], t_change: changepoints_t}\n",
    "#                                                 #tau: changepoint_prior_scale}))\n",
    "#                                  ) for _ in range(500)]).mean(axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Posterior check\n",
    "# kmean, kstddev = sess.run([qk.mean(), qk.stddev()])\n",
    "# print(\"Inferred posterior k: mean = %f, stddev = %f\" % (kmean, kstddev))\n",
    "# mmean, mstddev = sess.run([qm.mean(), qm.stddev()])\n",
    "# print(\"Inferred posterior m: mean = %f, stddev = %f\" % (mmean, mstddev))\n",
    "# tau_mean, tau_stddev = sess.run([qtau.mean(), qtau.stddev()])\n",
    "# print(\"Inferred posterior tau: mean = %f, stddev = %f\" % (tau_mean, tau_stddev))\n",
    "\n",
    "\n",
    "# noise_mean, noise_stddev = sess.run([qsigma_obs.mean(), qsigma_obs.stddev()])\n",
    "# print(\"Inferred posterior noise: mean = %f, stddev = %f\" % (noise_mean, noise_stddev))\n",
    "\n",
    "# nburn = 500\n",
    "# stride = 10\n",
    "# sns.distplot(qk.params.eval()[nburn:ITR:stride])\n",
    "# plt.show()\n",
    "# sns.distplot(qm.params.eval()[nburn:ITR:stride])\n",
    "# plt.show()\n",
    "\n",
    "# sns.distplot(qtau.params.eval()[nburn:ITR:stride])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
